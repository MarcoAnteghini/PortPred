{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PortPred-Pre-Alpha: overview and summary of the main analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some functions and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, h5py, torch\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "\n",
    "from typing import Union\n",
    "from bio_embeddings.utilities import read_fasta\n",
    "from bio_embeddings.embed import EmbedderInterface, SeqVecEmbedder\n",
    "#from bio_embeddings.embed import ProtTransBertBFDEmbedder, ESM1bEmbedder\n",
    "from tape import TAPETokenizer, UniRepModel, ProteinBertModel\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.metrics import confusion_matrix,f1_score,recall_score,roc_auc_score,fbeta_score,make_scorer,balanced_accuracy_score,accuracy_score,matthews_corrcoef\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import utils_trans_2\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_and_std_list(lr):\n",
    "    res = []\n",
    "    for x in zip(*lr):\n",
    "        res.append([sum(x)/len(x), np.std(x)])\n",
    "    return res\n",
    "\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    return specificity\n",
    "\n",
    "\n",
    "# Load the embedded sequence. Each of the following functions return either a dict (proteinID:embeddding_array) or just the embedding.\n",
    "def load_unirep_embedding(dire, dictio=False):\n",
    "    emb_list, emb_ids = [], []\n",
    "    for e in os.listdir(dire):\n",
    "        # print(e[:-11])\n",
    "        emb_list.append(np.load(dire+'/'+e))\n",
    "        ids = e[:-11]\n",
    "        emb_ids.append(str(ids))\n",
    "    emb = np.asarray(emb_list)\n",
    "    if dictio:\n",
    "        dic = {}\n",
    "        for i, j in zip(emb_ids, emb):\n",
    "            dic[i] = j\n",
    "        return dic, emb\n",
    "    else:\n",
    "        return emb\n",
    "\n",
    "\n",
    "def load_protbert_embedding(dire, dictio=False):\n",
    "    emb_list, emb_ids = [], []\n",
    "    for e in os.listdir(dire):\n",
    "        # print(e[:-11])\n",
    "        emb_list.append(np.load(dire+'/'+e))\n",
    "        ids = e[:-13]\n",
    "        emb_ids.append(str(ids))\n",
    "    emb = np.asarray(emb_list)\n",
    "    if dictio:\n",
    "        dic = {}\n",
    "        for i, j in zip(emb_ids, emb):\n",
    "            dic[i] = j\n",
    "        return dic, emb\n",
    "    else:\n",
    "        return emb\n",
    "\n",
    "\n",
    "def load_esmb1_embedding(dire, dictio=False):\n",
    "    emb_list, emb_ids = [], []\n",
    "    for e in os.listdir(dire):\n",
    "        # print(e[:-11])\n",
    "        emb_list.append(np.load(dire+'/'+e))\n",
    "        ids = e[:-10]\n",
    "        emb_ids.append(str(ids))\n",
    "    emb = np.asarray(emb_list)\n",
    "    if dictio:\n",
    "        dic = {}\n",
    "        for i, j in zip(emb_ids, emb):\n",
    "            dic[i] = j\n",
    "        return dic, emb\n",
    "    else:\n",
    "        return emb\n",
    "\n",
    "\n",
    "def load_seqvec_embedding(dire, dictio=False):\n",
    "    emb_list, emb_ids = [], []\n",
    "    for e in os.listdir(dire):\n",
    "        # print(e[:-11])\n",
    "        emb_list.append(np.load(dire+'/'+e))\n",
    "        ids = e[:-11]\n",
    "        emb_ids.append(str(ids))\n",
    "    emb = np.asarray(emb_list)\n",
    "    if dictio:\n",
    "        dic = {}\n",
    "        for i, j in zip(emb_ids, emb):\n",
    "            dic[i] = j\n",
    "        return dic, emb\n",
    "    else:\n",
    "        return emb\n",
    "\n",
    "# Input emb must be a string stating which embedding is desired among: 'esmb1', 'unirep', 'seqvec', 'protbert'\n",
    "\n",
    "\n",
    "def load_embedding(emb, dire, dictio=False):\n",
    "    if emb == 'unirep':\n",
    "        if dictio == True:\n",
    "            dic, emb = load_unirep_embedding(dire, dictio=True)\n",
    "            return dic, emb\n",
    "        else:\n",
    "            emb = load_unirep_embedding(dire, dictio=True)\n",
    "            return emb\n",
    "    if emb == 'seqvec':\n",
    "        if dictio == True:\n",
    "            dic, emb = load_seqvec_embedding(dire, dictio=True)\n",
    "            return dic, emb\n",
    "        else:\n",
    "            emb = load_seqvec_embedding(dire, dictio=True)\n",
    "            return emb\n",
    "    if emb == 'esmb1':\n",
    "        if dictio == True:\n",
    "            dic, emb = load_esmb1_embedding(dire, dictio=True)\n",
    "            return dic, emb\n",
    "        else:\n",
    "            emb = load_esmb1_embedding(dire, dictio=True)\n",
    "            return emb\n",
    "    if emb == 'protbert':\n",
    "        if dictio == True:\n",
    "            dic, emb = load_protbert_embedding(dire, dictio=True)\n",
    "            return dic, emb\n",
    "        else:\n",
    "            emb = load_protbert_embedding(dire, dictio=True)\n",
    "            return emb\n",
    "\n",
    "\n",
    "# FUNCTIONS USEFUL FOR CV AND GRIDSEARCH:\n",
    "def create_model_param_grid(method, class_weight, random_state=42):\n",
    "    if method == 'LR':\n",
    "        model = LogisticRegression(random_state=random_state)\n",
    "        param_grid = {'solver': ['liblinear', 'saga'],\n",
    "                      'penalty': ['l1', 'l2'],\n",
    "                      'C': np.logspace(-3, 9, 13),\n",
    "                      'class_weight': class_weight}\n",
    "    elif method == 'SVM':\n",
    "        model = SVC(random_state=random_state)\n",
    "        param_grid = {'C': np.logspace(-2, 10, 13),\n",
    "                      'gamma': np.logspace(-9, 3, 13),\n",
    "                      'class_weight': class_weight}\n",
    "    elif method == 'RF':\n",
    "        model = RandomForestClassifier(random_state=random_state)\n",
    "        param_grid = {'n_estimators': [15, 25, 50, 75, 100, 200, 300],\n",
    "                      'criterion': ['gini', 'entropy'],\n",
    "                      'max_depth': [2, 5, 10, None],\n",
    "                      'min_samples_split': [2, 4, 8, 10],\n",
    "                      'max_features': ['sqrt', 'auto', 'log2'],\n",
    "                      'class_weight': class_weight}\n",
    "    elif method == 'MLP':\n",
    "        model = MLPClassifier(random_state=random_state)\n",
    "        param_grid = {'hidden_layer_sizes': [(200,), (100,), (50,), (200, 100, 6, 1)],\n",
    "                      'activation': ['relu'],\n",
    "                      'solver': ['lbfgs'],\n",
    "                      'alpha': [1.0],\n",
    "                      'learning_rate': ['constant']}\n",
    "    return model, param_grid\n",
    "\n",
    "\n",
    "def create_X_y(pos, neg):\n",
    "    #pos=np.asarray([pos.values()[key] for key in pos.values()])\n",
    "    #neg=np.asarray([neg.values()[key] for key in neg.values()])\n",
    "    X = np.concatenate((pos, neg), axis=0)\n",
    "    y = np.concatenate((np.ones(len(pos)), np.zeros(len(neg))), axis=0)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEmbedder(EmbedderInterface):\n",
    "\n",
    "    name = \"onehot\"\n",
    "    number_of_layers = 1\n",
    "\n",
    "    def __init__(self, extended=False):\n",
    "        super().__init__()\n",
    "        if not extended:\n",
    "            self._AMINO_ACIDS = np.asarray(list(\"ACDEFGHIKLMNPQRSTVWY\"))\n",
    "        else:\n",
    "            self._AMINO_ACIDS = np.asarray(list(\"ACDEFGHIKLMNPQRSTVWYX\"))\n",
    "        self.embedding_dimension = len(self._AMINO_ACIDS)\n",
    "\n",
    "    def embed(self, sequence: str) -> np.ndarray:\n",
    "        sequence = re.sub(r\"[UZOB]\", \"X\", sequence)\n",
    "        if sum([s in self._AMINO_ACIDS for s in sequence]) == len(sequence):\n",
    "            return np.asarray([self._AMINO_ACIDS == s for s in sequence]).astype(np.float32)\n",
    "        else:\n",
    "            raise ValueError(\"Sequence contains unsupported characters.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def reduce_per_protein(embedding: np.ndarray) -> np.ndarray:\n",
    "        return embedding.mean(axis=0)\n",
    "\n",
    "\n",
    "class UniRepEmbedder(EmbedderInterface):\n",
    "\n",
    "    name = \"unirep\"\n",
    "    embedding_dimension = 1900\n",
    "    number_of_layers = 1\n",
    "\n",
    "    def __init__(self, device: Union[None, str, torch.device] = None, **kwargs):\n",
    "        super().__init__(device, **kwargs)\n",
    "        self._tokenizer = TAPETokenizer(vocab='unirep')\n",
    "        self._model = UniRepModel.from_pretrained('babbler-1900').eval().to(self._device)\n",
    "\n",
    "    def embed(self, sequence: str) -> np.ndarray:\n",
    "        token_ids = torch.tensor([self._tokenizer.encode(sequence)]).to(self._device)\n",
    "        with torch.no_grad():\n",
    "            return self._model(token_ids)[0].squeeze()[1:-1].cpu().numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def reduce_per_protein(embedding: np.ndarray) -> np.ndarray:\n",
    "        return embedding.mean(axis=0)\n",
    "\n",
    "\n",
    "def init_model(emb_name):\n",
    "    if emb_name == 'onehot':\n",
    "        model = OneHotEmbedder(extended=True)\n",
    "    elif emb_name == 'unirep':\n",
    "        model = UniRepEmbedder()\n",
    "    elif emb_name == 'seqvec':\n",
    "        model = SeqVecEmbedder()\n",
    "    elif emb_name == 'protbert':\n",
    "        model = ProtTransBertBFDEmbedder()\n",
    "    elif emb_name == 'esm1b':\n",
    "        model = ESM1bEmbedder()\n",
    "    return model\n",
    "    \n",
    "# function to obtain embedding\n",
    "def get_embedding(emb_name, model, sequence):\n",
    "    # embed sequence\n",
    "    if emb_name in ['onehot', 'unirep', 'protbert', 'esm1b']:\n",
    "        emb = model.embed(sequence)\n",
    "    elif emb_name == 'seqvec':\n",
    "        emb = model.embed(sequence)\n",
    "        emb = emb.sum(0) # sums over 3 layers\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples on how to generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_name='unirep' # CHANGE HERE\n",
    "#model = init_model(emb_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb = get_embedding(emb_name, model, seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename='Q9LVM1.fasta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(filename) as fastafile:\n",
    "#    seqs={}\n",
    "#    records = list(SeqIO.parse(fastafile, \"fasta\"))\n",
    "#    for record in records:\n",
    "#        if '|' not in record.id:\n",
    "#            idx = record.id\n",
    "#        else:\n",
    "#            idx = record.id.split('|')[1]\n",
    "#            seq = str(record.seq)\n",
    "#            seqs[idx] = seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_unirep=init_model('unirep')\n",
    "#model_seqvec=init_model('seqvec')\n",
    "#model_protbert=ProteinBertModel.from_pretrained('bert-base')\n",
    "#model_esmb1=ESM1bEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_demo_unirep = get_embedding('unirep',model_unirep, seqs['Q9LVM1'])\n",
    "#emb_demo_seqvec = get_embedding('seqvec',model_seqvec, seqs['Q9LVM1'])\n",
    "#emb_demo_protbert= get_embedding('protbert',model_protbert, seqs['Q9LVM1'])\n",
    "#emb_demo_esm1b= get_embedding('esm1b',model_esm1b, seqs['Q9LVM1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb_demo=np.concatenate((emb_demo_unirep,emb_demo_seqvec,emb_demo_protbert,emb_demo_esm1b),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in esmb1_dict_train.keys():\n",
    "#    full_train_dict_esmb_included[k]=np.concatenate((esmb1_dict_train[k],protbert_dict_train[k],seqvec_dict_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids(file):\n",
    "    ids=[]\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            ids.append(line.rstrip())\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset (training and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "protbert_dict_test,protbert_emb_test=load_embedding('protbert','ft_transporter_test_fasta_protbert',dictio=True)\n",
    "esmb1_dict_test,esmb1_emb_test=load_embedding('esmb1','ft_transporter_test_fasta_esm1b/',dictio=True)\n",
    "seqvec_dict_test,seqvec_emb_test=load_embedding('seqvec','ft_transporter_test_fasta_seqvec/',dictio=True)\n",
    "unirep_dict_test,unirep_emb_test=load_unirep_embedding('ft_transporter_test_fasta_unirep/',dictio=True)\n",
    "\n",
    "#train Ftrans\n",
    "protbert_dict_train_ft,protbert_emb_train_ft=load_embedding('protbert','dataset_ftrans/ft_transporter/ft_transporter_train_fasta_protbert/',dictio=True)\n",
    "esmb1_dict_train_ft,esmb1_emb_train_ft=load_embedding('esmb1','dataset_ftrans/ft_transporter/ft_transporter_train_fasta_esm1b/',dictio=True)\n",
    "seqvec_dict_train_ft,seqvec_emb_train_ft=load_embedding('seqvec','dataset_ftrans/ft_transporter/ft_transporter_train_fasta_seqvec/',dictio=True)\n",
    "unirep_dict_train_ft,unirep_emb_train_ft=load_unirep_embedding('dataset_ftrans/ft_transporter/ft_transporter_train_fasta_unirep/',dictio=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train \n",
    "amino_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/amino_train.ids')\n",
    "electro_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/electron_train.ids')\n",
    "sugar_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/sugar_train.ids')\n",
    "protein_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/protein_train.ids')\n",
    "hion_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/hion_train.ids')\n",
    "lipid_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/lipid_train.ids')\n",
    "other_ids_train=load_ids('dataset_ftrans/Dataset/Train20Fasta/others_train.ids')\n",
    "\n",
    "\n",
    "#test ftrans\n",
    "amino_ids_test=load_ids('Test20Fasta/Amino acid/amino.ids')\n",
    "electro_ids_test=load_ids('Test20Fasta/Electron/electro.ids')\n",
    "sugar_ids_test=load_ids('Test20Fasta/Sugar/sugar.ids')\n",
    "protein_ids_test=load_ids('Test20Fasta/Protein mRNA/proteinmrna.ids')\n",
    "hion_ids_test=load_ids('Test20Fasta/Hydrogen ion/Hion.ids')\n",
    "lipid_ids_test=load_ids('Test20Fasta/Lipid/lipid.ids')\n",
    "other_ids_test=load_ids('Test20Fasta/Others/others.ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amino  Ftrans  Uni,Seq,Pro,Esm: 61 61 61 61\n",
      "Test  Uni,Seq,Pro,Esm: 12 12 12 12\n",
      "\n",
      "\n",
      "Elect Ftrans   Uni,Seq,Pro,Esm: 184 184 184 181\n",
      "TEst Uni,Seq,Pro,Esm: 37 37 37 37\n",
      "\n",
      "\n",
      "Hion+ ftrans  Uni,Seq,Pro,Esm: 73 73 73 73\n",
      "Test Uni,Seq,Pro,Esm: 15 15 15 14\n",
      "\n",
      "\n",
      "Sugar Ftrans  Uni,Seq,Pro,Esm: 71 71 71 71\n",
      "Test Uni,Seq,Pro,Esm: 13 13 13 13\n",
      "\n",
      "\n",
      "Prote Ftrans  Uni,Seq,Pro,Esm: 380 380 380 330\n",
      "Test  Uni,Seq,Pro,Esm: 75 75 75 58\n",
      "\n",
      "\n",
      "Lipid  Uni,Seq,Pro,Esm: 66 66 66 52\n",
      "test  Uni,Seq,Pro,Esm: 12 12 12 9\n",
      "\n",
      "\n",
      "Other Ftrans  Uni,Seq,Pro,Esm: 165 165 165 152\n",
      "test  Uni,Seq,Pro,Esm: 33 33 33 32\n"
     ]
    }
   ],
   "source": [
    "##amino train ftrans\n",
    "amino_protbert_ft,amino_unirep_ft,amino_seqvec_ft,amino_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in amino_ids_train:\n",
    "        amino_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in amino_ids_train:\n",
    "        amino_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in amino_ids_train:\n",
    "        amino_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in amino_ids_train:\n",
    "        amino_esmb1_ft[k]=v\n",
    "print('Amino  Ftrans  Uni,Seq,Pro,Esm: '+str(len(amino_unirep_ft))+' '+str(len(amino_seqvec_ft))+' '+\\\n",
    "      str(len(amino_protbert_ft))+' '+str(len(amino_esmb1_ft)))\n",
    "\n",
    "##amino test ftrans\n",
    "amino_protbert_test,amino_unirep_test,amino_seqvec_test,amino_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in amino_ids_test:\n",
    "        amino_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in amino_ids_test:\n",
    "        amino_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in amino_ids_test:\n",
    "        amino_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in amino_ids_test:\n",
    "        amino_esmb1_test[k]=v\n",
    "print('Test  Uni,Seq,Pro,Esm: '+str(len(amino_unirep_test))+' '+str(len(amino_seqvec_test))+' '+\\\n",
    "      str(len(amino_protbert_test))+' '+str(len(amino_esmb1_test)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "##electro train ftrans\n",
    "electro_protbert_ft,electro_unirep_ft,electro_seqvec_ft,electro_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in electro_ids_train:\n",
    "        electro_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in electro_ids_train:\n",
    "        electro_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in electro_ids_train:\n",
    "        electro_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in electro_ids_train:\n",
    "        electro_esmb1_ft[k]=v\n",
    "print('Elect Ftrans   Uni,Seq,Pro,Esm: '+str(len(electro_unirep_ft))+' '+str(len(electro_seqvec_ft))+' '+\\\n",
    "      str(len(electro_protbert_ft))+' '+str(len(electro_esmb1_ft)))\n",
    "\n",
    "#electro test\n",
    "electro_protbert_test,electro_unirep_test,electro_seqvec_test,electro_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in electro_ids_test:\n",
    "        electro_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in electro_ids_test:\n",
    "        electro_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in electro_ids_test:\n",
    "        electro_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in electro_ids_test:\n",
    "        electro_esmb1_test[k]=v\n",
    "print('TEst Uni,Seq,Pro,Esm: '+str(len(electro_unirep_test))+' '+str(len(electro_seqvec_test))+' '+\\\n",
    "      str(len(electro_protbert_test))+' '+str(len(electro_esmb1_test)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#hion train ftrans\n",
    "hion_protbert_ft,hion_unirep_ft,hion_seqvec_ft,hion_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in hion_ids_train:\n",
    "        hion_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in hion_ids_train:\n",
    "        hion_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in hion_ids_train:\n",
    "        hion_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in hion_ids_train:\n",
    "        hion_esmb1_ft[k]=v\n",
    "print('Hion+ ftrans  Uni,Seq,Pro,Esm: '+str(len(hion_unirep_ft))+' '+str(len(hion_seqvec_ft))+' '+\\\n",
    "      str(len(hion_protbert_ft))+' '+str(len(hion_esmb1_ft)))\n",
    "\n",
    "#hion test\n",
    "hion_protbert_test,hion_unirep_test,hion_seqvec_test,hion_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in hion_ids_test:\n",
    "        hion_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in hion_ids_test:\n",
    "        hion_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in hion_ids_test:\n",
    "        hion_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in hion_ids_test:\n",
    "        hion_esmb1_test[k]=v\n",
    "print('Test Uni,Seq,Pro,Esm: '+str(len(hion_unirep_test))+' '+str(len(hion_seqvec_test))+' '+\\\n",
    "      str(len(hion_protbert_test))+' '+str(len(hion_esmb1_test)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#sugar train Ftrans\n",
    "sugar_protbert_ft,sugar_unirep_ft,sugar_seqvec_ft,sugar_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in sugar_ids_train:\n",
    "        sugar_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in sugar_ids_train:\n",
    "        sugar_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in sugar_ids_train:\n",
    "        sugar_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in sugar_ids_train:\n",
    "        sugar_esmb1_ft[k]=v\n",
    "print('Sugar Ftrans  Uni,Seq,Pro,Esm: '+str(len(sugar_unirep_ft))+' '+str(len(sugar_seqvec_ft))+' '+\\\n",
    "      str(len(sugar_protbert_ft))+' '+str(len(sugar_esmb1_ft)))\n",
    "\n",
    "#sugar test\n",
    "sugar_protbert_test,sugar_unirep_test,sugar_seqvec_test,sugar_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in sugar_ids_test:\n",
    "        sugar_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in sugar_ids_test:\n",
    "        sugar_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in sugar_ids_test:\n",
    "        sugar_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in sugar_ids_test:\n",
    "        sugar_esmb1_test[k]=v\n",
    "print('Test Uni,Seq,Pro,Esm: '+str(len(sugar_unirep_test))+' '+str(len(sugar_seqvec_test))+' '+\\\n",
    "      str(len(sugar_protbert_test))+' '+str(len(sugar_esmb1_test)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#protein train Ftrans\n",
    "protein_protbert_ft,protein_unirep_ft,protein_seqvec_ft,protein_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in protein_ids_train:\n",
    "        protein_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in protein_ids_train:\n",
    "        protein_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in protein_ids_train:\n",
    "        protein_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in protein_ids_train:\n",
    "        protein_esmb1_ft[k]=v\n",
    "print('Prote Ftrans  Uni,Seq,Pro,Esm: '+str(len(protein_unirep_ft))+' '+str(len(protein_seqvec_ft))+' '+\\\n",
    "      str(len(protein_protbert_ft))+' '+str(len(protein_esmb1_ft)))\n",
    "\n",
    "#protein test\n",
    "protein_protbert_test,protein_unirep_test,protein_seqvec_test,protein_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in protein_ids_test:\n",
    "        protein_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in protein_ids_test:\n",
    "        protein_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in protein_ids_test:\n",
    "        protein_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in protein_ids_test:\n",
    "        protein_esmb1_test[k]=v\n",
    "print('Test  Uni,Seq,Pro,Esm: '+str(len(protein_unirep_test))+' '+str(len(protein_seqvec_test))+' '+\\\n",
    "      str(len(protein_protbert_test))+' '+str(len(protein_esmb1_test)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#lipid train Ftrans\n",
    "lipid_protbert_ft,lipid_unirep_ft,lipid_seqvec_ft,lipid_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in lipid_ids_train:\n",
    "        lipid_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in lipid_ids_train:\n",
    "        lipid_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in lipid_ids_train:\n",
    "        lipid_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in lipid_ids_train:\n",
    "        lipid_esmb1_ft[k]=v\n",
    "print('Lipid  Uni,Seq,Pro,Esm: '+str(len(lipid_unirep_ft))+' '+str(len(lipid_seqvec_ft))+' '+\\\n",
    "      str(len(lipid_protbert_ft))+' '+str(len(lipid_esmb1_ft)))\n",
    "\n",
    "#lipid test\n",
    "lipid_protbert_test,lipid_unirep_test,lipid_seqvec_test,lipid_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in lipid_ids_test:\n",
    "        lipid_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in lipid_ids_test:\n",
    "        lipid_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in lipid_ids_test:\n",
    "        lipid_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in lipid_ids_test:\n",
    "        lipid_esmb1_test[k]=v\n",
    "print('test  Uni,Seq,Pro,Esm: '+str(len(lipid_unirep_test))+' '+str(len(lipid_seqvec_test))+' '+\\\n",
    "      str(len(lipid_protbert_test))+' '+str(len(lipid_esmb1_test)))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#other train Ftrans\n",
    "other_protbert_ft,other_unirep_ft,other_seqvec_ft,other_esmb1_ft={},{},{},{}\n",
    "for k,v in protbert_dict_train_ft.items():\n",
    "    if k in other_ids_train:\n",
    "        other_protbert_ft[k]=v\n",
    "for k,v in unirep_dict_train_ft.items():\n",
    "    if k in other_ids_train:\n",
    "        other_unirep_ft[k]=v\n",
    "for k,v in seqvec_dict_train_ft.items():\n",
    "    if k in other_ids_train:\n",
    "        other_seqvec_ft[k]=v\n",
    "for k,v in esmb1_dict_train_ft.items():\n",
    "    if k in other_ids_train:\n",
    "        other_esmb1_ft[k]=v\n",
    "print('Other Ftrans  Uni,Seq,Pro,Esm: '+str(len(other_unirep_ft))+' '+str(len(other_seqvec_ft))+' '+\\\n",
    "      str(len(other_protbert_ft))+' '+str(len(other_esmb1_ft)))\n",
    "\n",
    "#other test\n",
    "other_protbert_test,other_unirep_test,other_seqvec_test,other_esmb1_test={},{},{},{}\n",
    "for k,v in protbert_dict_test.items():\n",
    "    if k in other_ids_test:\n",
    "        other_protbert_test[k]=v\n",
    "for k,v in unirep_dict_test.items():\n",
    "    if k in other_ids_test:\n",
    "        other_unirep_test[k]=v\n",
    "for k,v in seqvec_dict_test.items():\n",
    "    if k in other_ids_test:\n",
    "        other_seqvec_test[k]=v\n",
    "for k,v in esmb1_dict_test.items():\n",
    "    if k in other_ids_test:\n",
    "        other_esmb1_test[k]=v\n",
    "print('test  Uni,Seq,Pro,Esm: '+str(len(other_unirep_test))+' '+str(len(other_seqvec_test))+' '+\\\n",
    "      str(len(other_protbert_test))+' '+str(len(other_esmb1_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seqvec_test=np.asarray(list(other_seqvec_test.values())[:len(other_esmb1_test)]+\\\n",
    "                          list(electro_seqvec_test.values())[:len(electro_esmb1_test)]+\\\n",
    "                          list(hion_seqvec_test.values())[:len(hion_esmb1_test)]+\\\n",
    "                          list(protein_seqvec_test.values())[:len(protein_esmb1_test)]+\\\n",
    "                          list(sugar_seqvec_test.values())+\\\n",
    "                          list(lipid_seqvec_test.values())[:len(lipid_esmb1_test)]+\\\n",
    "                          list(amino_seqvec_test.values()))\n",
    "X_unirep_test=np.asarray(list(other_unirep_test.values())[:len(other_esmb1_test)]+\\\n",
    "                          list(electro_unirep_test.values())[:len(electro_esmb1_test)]+\\\n",
    "                          list(hion_unirep_test.values())[:len(hion_esmb1_test)]+\\\n",
    "                          list(protein_unirep_test.values())[:len(protein_esmb1_test)]+\\\n",
    "                          list(sugar_unirep_test.values())+\\\n",
    "                          list(lipid_unirep_test.values())[:len(lipid_esmb1_test)]+\\\n",
    "                          list(amino_unirep_test.values()))\n",
    "X_protbert_test=np.asarray(list(other_protbert_test.values())[:len(other_esmb1_test)]+\\\n",
    "                          list(electro_protbert_test.values())[:len(electro_esmb1_test)]+\\\n",
    "                          list(hion_protbert_test.values())[:len(hion_esmb1_test)]+\\\n",
    "                          list(protein_protbert_test.values())[:len(protein_esmb1_test)]+\\\n",
    "                          list(sugar_protbert_test.values())+\\\n",
    "                          list(lipid_protbert_test.values())[:len(lipid_esmb1_test)]+\\\n",
    "                          list(amino_protbert_test.values()))\n",
    "X_esmb1_test=np.asarray(list(other_esmb1_test.values())+list(electro_esmb1_test.values())+\\\n",
    "                          list(hion_esmb1_test.values())+list(protein_esmb1_test.values())+\\\n",
    "                          list(sugar_esmb1_test.values())+list(lipid_esmb1_test.values())+\\\n",
    "                          list(amino_esmb1_test.values()))\n",
    "#X_unirep_train=np.asarray(list(unirep_dict_train.values()))\n",
    "X_test=np.concatenate((X_unirep_test,X_seqvec_test,X_protbert_test,X_esmb1_test),axis=1)\n",
    "\n",
    "\n",
    "X_seqvec_train_ft=np.asarray(list(other_seqvec_ft.values())[:len(other_esmb1_ft)]+\\\n",
    "                          list(electro_seqvec_ft.values())[:len(electro_esmb1_ft)]+\\\n",
    "                          list(hion_seqvec_ft.values())[:len(hion_esmb1_ft)]+\\\n",
    "                          list(protein_seqvec_ft.values())[:len(protein_esmb1_ft)]+\\\n",
    "                          list(sugar_seqvec_ft.values())+\\\n",
    "                          list(lipid_seqvec_ft.values())[:len(lipid_esmb1_ft)]+\\\n",
    "                          list(amino_seqvec_ft.values()))\n",
    "X_unirep_train_ft=np.asarray(list(other_unirep_ft.values())[:len(other_esmb1_ft)]+\\\n",
    "                          list(electro_unirep_ft.values())[:len(electro_esmb1_ft)]+\\\n",
    "                          list(hion_unirep_ft.values())[:len(hion_esmb1_ft)]+\\\n",
    "                          list(protein_unirep_ft.values())[:len(protein_esmb1_ft)]+\\\n",
    "                          list(sugar_unirep_ft.values())+\\\n",
    "                          list(lipid_unirep_ft.values())[:len(lipid_esmb1_ft)]+\\\n",
    "                          list(amino_unirep_ft.values()))\n",
    "X_protbert_train_ft=np.asarray(list(other_protbert_ft.values())[:len(other_esmb1_ft)]+\\\n",
    "                          list(electro_protbert_ft.values())[:len(electro_esmb1_ft)]+\\\n",
    "                          list(hion_protbert_ft.values())[:len(hion_esmb1_ft)]+\\\n",
    "                          list(protein_protbert_ft.values())[:len(protein_esmb1_ft)]+\\\n",
    "                          list(sugar_protbert_ft.values())+\\\n",
    "                          list(lipid_protbert_ft.values())[:len(lipid_esmb1_ft)]+\\\n",
    "                          list(amino_protbert_ft.values()))\n",
    "X_esmb1_train_ft=np.asarray(list(other_esmb1_ft.values())+list(electro_esmb1_ft.values())+\\\n",
    "                          list(hion_esmb1_ft.values())+list(protein_esmb1_ft.values())+\\\n",
    "                          list(sugar_esmb1_ft.values())+list(lipid_esmb1_ft.values())+\\\n",
    "                          list(amino_esmb1_ft.values()))\n",
    "#X_unirep_train=np.asarray(list(unirep_dict_train.values()))\n",
    "X_train_ft=np.concatenate((X_unirep_train_ft,X_seqvec_train_ft,X_protbert_train_ft,X_esmb1_train_ft),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.asarray([0]*(len(other_esmb1_test))+[1]*len(electro_esmb1_test)+[2]*len(hion_esmb1_test)+\\\n",
    "             [3]*(len(protein_esmb1_test))+[4]*len(sugar_esmb1_test)+\\\n",
    "             [5]*(len(lipid_esmb1_test))+[6]*len(amino_esmb1_test))\n",
    "\n",
    "y_train_ft=np.asarray([0]*(len(other_esmb1_ft))+[1]*len(electro_esmb1_ft)+[2]*len(hion_esmb1_ft)+\\\n",
    "             [3]*(len(protein_esmb1_ft))+[4]*len(sugar_esmb1_ft)+\\\n",
    "             [5]*(len(lipid_esmb1_ft))+[6]*len(amino_esmb1_ft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The main function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_embedding_RFE2(x,y,methods=['LR'],return_embedding_columns=True,random_state=[42],n_jobs=-1,\\\n",
    "                                     folds=10,refit='f1_macro',class_weight=[{0:1,1:1}],war='ignore',\\\n",
    "                                     results_filename='RESULTS'):\n",
    "    class_weight=class_weight\n",
    "    folds=folds\n",
    "    refit=refit\n",
    "    \n",
    "    if war=='ignore':\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        for method in tqdm(methods, desc=\"Methods\"):\n",
    "            model_best_res=0\n",
    "            results_iteration=[]\n",
    "            for rs in tqdm(random_states, desc=\"random states\"):\n",
    "                current_best = 0\n",
    "                cv = StratifiedKFold(n_splits=folds,shuffle=True,random_state=rs)\n",
    "                M,p=create_model_param_grid(method,class_weight,random_state=rs)\n",
    "                #print(M)\n",
    "                mp = GridSearchCV(M, param_grid=p, cv=cv, return_train_score=True,\\\n",
    "                                scoring ={\n",
    "                                'f1_macro':make_scorer(f1_score, average='macro'),\\\n",
    "                                'mcc':make_scorer(matthews_corrcoef)},\\\n",
    "                                verbose=1,n_jobs=n_jobs,refit=refit)\n",
    "                \n",
    "                           \n",
    "                \n",
    "                #print(mp)\n",
    "                mp.verbose = False\n",
    "                mp.fit(x,y)        \n",
    "\n",
    "                results_full_1 = pd.DataFrame(pd.DataFrame(mp.cv_results_))\n",
    "                \n",
    "                results_rank=results_full_1.sort_values(by=['rank_test_f1_macro'])\n",
    "                res=results_rank.filter(items=['mean_test_f1_macro','mean_test_mcc'])[:1].values[0]\n",
    "\n",
    "                best_params = mp.best_params_\n",
    "\n",
    "                current_results = mp.best_score_\n",
    "\n",
    "                if current_results.max() > current_best:\n",
    "                    current_best = current_results.max()\n",
    "                    final_res=res\n",
    "                            \n",
    "                else:\n",
    "                    break\n",
    "                            \n",
    "\n",
    "                results_iteration.append(final_res)\n",
    "\n",
    "            all_res=avg_and_std_list(results_iteration)\n",
    "            new_dict={}\n",
    "            new_v=[]\n",
    "            for lista in all_res:\n",
    "                new_v.append([round(lista[0],4),round(lista[1],4)])\n",
    "            new_dict['score']=new_v\n",
    "            res_df=pd.DataFrame(new_dict)\n",
    "            newcol=['f1_macro','mcc']\n",
    "\n",
    "            res_df.insert(loc=0, column='metrics', value=newcol)\n",
    "            res_df.to_csv(results_filename+'_'+method+'.csv',sep='\\t')\n",
    "            print('all features results:'+'\\n',method,res_df)\n",
    "            if method == 'LR':\n",
    "                estimator = LogisticRegression(**best_params,multi_class='auto')\n",
    "            else:\n",
    "                mod = np.load('LRbest_hybrid_model_multiclass.sav',allow_pickle=True)\n",
    "                estimator = mod\n",
    "            list_of_n_of_selected_features,list_of_feature_ranks=[],[]    \n",
    "            \n",
    "            selector = RFECV(estimator,cv=folds, min_features_to_select=100, step=100, scoring='f1_macro')\n",
    "            sel = selector.fit(x, y)\n",
    "            n_of_selected_features=sel.n_features_\n",
    "            list_of_n_of_selected_features.append(n_of_selected_features)\n",
    "            list_of_feature_ranks.append(sel.ranking_)\n",
    "            lofosf=np.asarray(list_of_n_of_selected_features)\n",
    "            avg_n_of_selected_features=np.mean(lofosf)\n",
    "            columns_list=[]\n",
    "            df_x=pd.DataFrame(x)\n",
    "            for i,j in zip(list_of_feature_ranks[0],df_x.columns):\n",
    "                if i==1:\n",
    "                    columns_list.append(j)\n",
    "            columns4_emb=np.asarray(columns_list)\n",
    "            with open('columns4_emb_multiclass.txt' ,'w') as f:\n",
    "                for e in columns4_emb:\n",
    "                    f.write(str(e)+'\\t')\n",
    "            new_emb=df_x[columns4_emb]\n",
    "            print('\\n')\n",
    "            print('New embedding shape:',new_emb.shape)\n",
    "            results_iteration =[]\n",
    "            for rs in tqdm(random_states, desc=\"random states RFE\"):\n",
    "                current_best = 0\n",
    "                cv = StratifiedKFold(n_splits=folds,shuffle=True,random_state=rs)\n",
    "                M,p=create_model_param_grid(method,class_weight,random_state=rs)\n",
    "                mp = GridSearchCV(M, param_grid=p, cv=cv, return_train_score=True,\\\n",
    "                                              scoring ={'f1_macro':make_scorer(f1_score, average='macro'),\\\n",
    "                                                        'mcc':make_scorer(matthews_corrcoef),\\\n",
    "                                                      },\\\n",
    "                                  verbose=1,n_jobs=n_jobs,refit=refit)\n",
    "\n",
    "                mp.verbose = False\n",
    "                mp.fit(new_emb,y)\n",
    "                        \n",
    "\n",
    "                results_full = pd.DataFrame(pd.DataFrame(mp.cv_results_))\n",
    "                results_rank=results_full.sort_values(by=['rank_test_f1_macro'])\n",
    "                res=results_rank.filter(items=['mean_test_f1_macro','mean_test_mcc','mean_test_accuracy'])[:1].values[0]\n",
    "\n",
    "                best_params = mp.best_params_\n",
    "\n",
    "                current_results = mp.best_score_\n",
    "\n",
    "                if current_results.max() > current_best:\n",
    "                    current_best = current_results.max()\n",
    "                    final_res=res\n",
    "                    #best_model=mp.best_estimator_\n",
    "                        \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "                results_iteration.append(final_res)\n",
    "                \n",
    "                if final_res[0]>model_best_res:\n",
    "                    model_best_res=final_res[0]\n",
    "                    best_model=mp.best_estimator_\n",
    "                    \n",
    "            filename = results_filename+'_'+method+'best_hybrid_model_multiclass.sav'\n",
    "            pickle.dump(best_model, open(filename, 'wb'))\n",
    "                    \n",
    "            \n",
    "            all_res=avg_and_std_list(results_iteration)\n",
    "            new_dict={}\n",
    "            new_v=[]\n",
    "            for lista in all_res:\n",
    "                new_v.append([round(lista[0],4),round(lista[1],4)])\n",
    "            new_dict['score']=new_v\n",
    "            res_df=pd.DataFrame(new_dict)\n",
    "            newcol=['f1_macro','mcc']\n",
    "\n",
    "            res_df.insert(loc=0, column='metrics', value=newcol)\n",
    "            res_df.to_csv(results_filename+'RFE'+'_'+method+'.csv',sep='\\t')\n",
    "            print('selected_features:'+'\\n',method,res_df)\n",
    "            if return_embedding_columns==True:\n",
    "                return columns4_emb,best_model\n",
    "            else:\n",
    "                return best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ea9c7c4e1548b383b121cd10de0fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Methods', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd1acda840e46189818e649f67e8021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='random states', max=1.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "methods=['LR'] # add SVM,MLP,RF\n",
    "random_states=[10] # add any random state (original analisis with 10)\n",
    "\n",
    "#execute the main funcion showing results with all the concatenated embeddings and with the RFE embeddings\n",
    "#for the multiclass prediction and save the hybird embedding.\n",
    "#the selected features will be stored in a file called columns4_emb_multiclass.txt\n",
    "features_selected,model=hybrid_embedding_RFE2(X_train_ft,y_train_ft,methods=methods,random_state=random_states,n_jobs=-1,results_filename='FT_multiclass_trainingsetCV_results')\n",
    "\n",
    "#load the binary classification model and the multiclass model\n",
    "model1=np.load('uni_prot_seqvec_ESMB_trainingsetCV_results_LR_all_features_model.sav',allow_pickle=True)\n",
    "model2=model\n",
    "#np.load('FT_multiclass_trainingsetCV_results_LRbest_hybrid_model_multiclass.sav',allow_pickle=True)\n",
    "df_x=pd.DataFrame(X_test)\n",
    "new_emb=df_x[features_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary=model1.predict(X_test)\n",
    "y_pred=model2.predict(new_emb)\n",
    "multilabel_confusion_matrix(y_pred,y_test)\n",
    "class_names=['other','electron','anion','protein_mrna','aminoacid','cation','sugar']\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# # Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# # Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# # Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# # Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# # Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# # False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# # False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# # Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "F1=f1_score(y_test,y_pred,average='macro')\n",
    "MCC=matthews_corrcoef(y_test,y_pred)\n",
    "\n",
    "print('Binary prediction:',y_pred_binary)\n",
    "print('\\n'+'F1 score for multiclass: '+str(F1))\n",
    "print('\\n'+'MCC score for multiclass: '+str(MCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10, 10))\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.set_title('Confusion Matrix', fontsize=25)\n",
    "ax.set_xticklabels(class_names,fontsize=12)\n",
    "ax.set_yticklabels(class_names,fontsize=12) \n",
    "ax.set_xlabel('Predicted label',fontsize=20)\n",
    "ax.set_ylabel('True label',fontsize=20)\n",
    "#ax.xcorr(new_emb,y_test)\n",
    "plot_confusion_matrix(model, new_emb, y_test, ax=ax, values_format='d',\n",
    "                                 display_labels=class_names, xticks_rotation='vertical',\n",
    "                                 cmap=plt.cm.Blues)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
